#-- Copyright 2023 Google LLC
#--
#-- Licensed under the Apache License, Version 2.0 (the "License");
#-- you may not use this file except in compliance with the License.
#-- You may obtain a copy of the License at
#--
#--     https://www.apache.org/licenses/LICENSE-2.0
#--
#-- Unless required by applicable law or agreed to in writing, software
#-- distributed under the License is distributed on an "AS IS" BASIS,
#-- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#-- See the License for the specific language governing permissions and
#-- limitations under the License.

# This build file generates all the necessary objects (DAG files, Bigquery
# tables and views etc) for a Cortex deployment for a Salesforce system.

# Input parameters:
#   _GCS_LOGS_BUCKET : An existing GCS bucket where build logs will be written.
#   _TGT_BUCKET : An existing GCS bucket where generated files related to
#                 Airflow DAGs(DAG py file, dependencies, DAG sql file etc)
#                 will be copied over to.
#   _DEPLOY_CDC : Whether to deploy CDC DAGs, true or false.

steps:
  - name: 'gcr.io/kittycorn-public/deploy-kittycorn:v2.0'
    entrypoint: /bin/bash
    args:
    - -c
    - |
      set -e
      export PYTHONPATH=$$PYTHONPATH:./src
      export create_mapping_views=$(cat 'config/sfdc_config.json' | python -c "import json,sys; print(str(json.load(sys.stdin)['SFDC']['createMappingViews']).lower())" 2>/dev/null || echo true)
      if [[ "$_DEPLOY_CDC" == "true" ]]
      then
        # RAW DAG generation
        echo "Generating Raw DAGs and SQL files."
        python src/raw_dag_generator/generate_dags.py
        echo "âœ… Generated Raw DAGs and SQL files."
        # If create_mapping_views is true, we won't create CDC DAGs.
        if [[ "${create_mapping_views}" != "true" ]]
        then
          # CDC DAG generation
          echo "Generating CDC DAGs and SQL files."
          python src/cdc_dag_generator/generate_dags.py
          echo "âœ… Generated CDC DAGs and SQL files."
        fi
        # Copy generated DAG sql files to Target GCS bucket
        generated_files=$(shopt -s nullglob dotglob; echo generated_sql/*.sql)
        if (( ${#generated_files} ))
        then
          echo "Copying SQL files to gs://${_TGT_BUCKET}/data/bq_data_replication."
          gsutil -m cp -r 'generated_sql/*.sql' gs://${_TGT_BUCKET}/data/bq_data_replication
          echo "âœ… SQL files have been copied."
        else
          echo "ðŸ”ªðŸ”ªðŸ”ªNo SQL files found under generated_sql folder or the folder does not exist. Skipping copy.ðŸ”ªðŸ”ªðŸ”ª"
        fi
        # Copy generated DAG python and related files to Target GCS bucket
        generated_files=$(shopt -s nullglob dotglob; echo ./generated_dag/*)
        if (( ${#generated_files} ))
        then
          echo "Copying DAG files to gs://${_TGT_BUCKET}/dags."
          gsutil -m cp -r './generated_dag/*' gs://'${_TGT_BUCKET}'/dags
          echo "âœ… DAG files have been copied."
        else
          echo "ðŸ”ªðŸ”ªðŸ”ªNo Python files found under generated_dag folder or the folder does not exist. Skipping copy.ðŸ”ªðŸ”ªðŸ”ª"
        fi
      fi
      # If create_mapping_views is true, we create CDC views.
      if [[ "${create_mapping_views}" == "true" ]]
      then
        # CDC view generation
        echo "Generating CDC views."
        python src/cdc_dag_generator/generate_views.py
        echo "âœ… CDC views have been generated."
      fi

  # Generate SFDC Reporting bigquery views and fucntions.
  - name: "gcr.io/kittycorn-public/deploy-kittycorn:v2.0"
    entrypoint: /bin/bash
    args:
    - -c
    - |
      src/reporting/deploy.sh "${_GCS_LOGS_BUCKET}"

logsBucket: "gs://$_GCS_LOGS_BUCKET"
timeout: 10200s
options:
  substitution_option: "ALLOW_LOOSE"
